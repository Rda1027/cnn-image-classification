{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPIgz1GLB0h7"
      },
      "source": [
        "## Initial set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag0Qr8AcCc_7",
        "outputId": "cc05e29f-3d35-4de8-cce2-c4ee1ca27987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (0.17.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (2.32.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (2.4.0)\n",
            "Requirement already satisfied: setproctitle in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from wandb) (69.5.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/rda1027/miniconda3/envs/ai/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jjHH2ztBmfh",
        "outputId": "541268d0-fd04-4dd2-e852-5c87c28f917c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms as T\n",
        "import wandb\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "#For saving the result of the training in a dirve folder \n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J10nUfL4CJao"
      },
      "source": [
        "Initialization of the device and fixing the reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1pWtCQqB8eM",
        "outputId": "0c70cfcb-9199-4924-83ef-958d20090aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"\n",
        "        Fix all the possible sources of randomness.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "fix_random(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Configurations\n",
        "\n",
        "cfg_data = {\n",
        "    'std_size' : 224,\n",
        "    'rand_crop_size' : 150,\n",
        "    'n_classes' : 43,\n",
        "}\n",
        "\n",
        "cfg_hyp = {\n",
        "    'lr' : 1e-3,\n",
        "    'wd' : 1e-5,\n",
        "    'epochs' : 50,\n",
        "    'batch_size' : 32,\n",
        "    'scheduler' : True,\n",
        "    'device' : device,\n",
        "    'stopping_patience' : 10,\n",
        "    'stopping_value' : 0.6\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8PDUd2VCwHU"
      },
      "source": [
        "## Download and exploration of the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj0R7eZECvdL",
        "outputId": "4b1bce30-0510-43e2-a13b-7643cb2ad03a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GroceryStoreDataset'...\n",
            "remote: Enumerating objects: 6559, done.\u001b[K\n",
            "remote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 6559 (delta 45), reused 35 (delta 35), pack-reused 6293 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6559/6559), 116.26 MiB | 15.15 MiB/s, done.\n",
            "Resolving deltas: 100% (275/275), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/marcusklasson/GroceryStoreDataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5HC3ne7OCqPu"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MatJWVyvoNr2"
      },
      "outputs": [],
      "source": [
        "class GroceryStoreDataset(Dataset):\n",
        "\n",
        "    def __init__(self, split: str, transform=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.root = Path(\"GroceryStoreDataset/dataset\")\n",
        "        self.split = split\n",
        "        self.paths, self.labels = self.read_file()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
        "        img = Image.open(self.root / self.paths[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def read_file(self) -> Tuple[List[str], List[int]]:\n",
        "        paths = []\n",
        "        labels = []\n",
        "\n",
        "        with open(self.root / f\"{self.split}.txt\") as f:\n",
        "            for line in f:\n",
        "                # path, fine-grained class, coarse-grained class\n",
        "                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n",
        "                paths.append(path), labels.append(int(label))\n",
        "\n",
        "        return paths, labels\n",
        "\n",
        "    def get_num_classes(self) -> int:\n",
        "        return max(self.labels) + 1\n",
        "    \n",
        "    #My adding for balance the dataset\n",
        "    def get_class_weights(self) -> torch.Tensor:\n",
        "        class_counts = np.bincount(self.labels)\n",
        "        class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "        return class_weights\n",
        "\n",
        "    def get_sampler(self) -> WeightedRandomSampler:\n",
        "        class_weights = self.get_class_weights()\n",
        "        sample_weights = [class_weights[label] for label in self.labels]\n",
        "        return WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAYUtT7mpWAA",
        "outputId": "4f8cd374-7a7a-43b3-e552-0c4a5ac464f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 2640\n",
            "Increased train dataset size: 5280\n",
            "Validation dataset size: 296\n",
            "Test dataset size: 2485\n"
          ]
        }
      ],
      "source": [
        "## Rimettere a 260x260 o a 224x224 (per resnet)\n",
        "\n",
        "n_classes = cfg_data['n_classes']\n",
        "\n",
        "tsfms_std = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Resize(size=(cfg_data['std_size'], cfg_data['std_size'])),\n",
        "    # T.Lambda(lambda x: x.flatten()),\n",
        "])\n",
        "\n",
        "#DATA AUGMENTATION\n",
        "#tsfms_increasing = T.Compose([\n",
        "#    T.RandomRotation(15),\n",
        "#    T.RandomResizedCrop(32, scale=(0.9, 1.1)),\n",
        "#    T.RandomHorizontalFlip(),\n",
        "#    T.RandomResizedCrop(size=(cfg_data['rand_crop_size'], cfg_data['rand_crop_size']), scale=(0.7, 0.9)),\n",
        "#    T.ToTensor(),\n",
        "#    T.Resize(size=(cfg_data['std_size'], cfg_data['std_size'])),\n",
        "#    # T.Lambda(lambda x: x.flatten()),\n",
        "#])\n",
        "\n",
        "\n",
        "#NEWDATAAUGMENTATION\n",
        "class RandomApply(T.RandomApply):\n",
        "    def __init__(self, transforms, p=0.5):\n",
        "        super().__init__(transforms, p=p)\n",
        "\n",
        "def change_background_color(image):\n",
        "    background = Image.new('RGB', image.size, (random.randint(200, 255), random.randint(200, 255), random.randint(200, 255)))\n",
        "    return Image.composite(image, background, image.convert('L').point(lambda x: 255 if x > 5 else 0))\n",
        "\n",
        "\n",
        "tsfms_increasing = T.Compose([\n",
        "        T.RandomRotation(10),\n",
        "        T.RandomResizedCrop(32, scale=(0.9, 1.0)),\n",
        "        T.RandomHorizontalFlip(p=0.3),\n",
        "        RandomApply([T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.7),\n",
        "        RandomApply([T.GaussianBlur(kernel_size=3)], p=0.2),\n",
        "        T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "        RandomApply([T.Lambda(change_background_color)], p=0.3),\n",
        "        T.RandomResizedCrop(size=(cfg_data['rand_crop_size'], cfg_data['rand_crop_size']), scale=(0.8, 1.0)),\n",
        "        T.ToTensor(),\n",
        "        T.Resize(size=(cfg_data['std_size'], cfg_data['std_size'])),\n",
        "        RandomApply([\n",
        "            T.Lambda(lambda x: x + 0.02 * torch.randn_like(x))\n",
        "        ], p=0.2),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "train_dset = GroceryStoreDataset(\n",
        "    split=\"train\",\n",
        "    transform=tsfms_std,\n",
        ")\n",
        "increased_train_dst = GroceryStoreDataset(\n",
        "    split=\"train\",\n",
        "    transform=tsfms_increasing,\n",
        ")\n",
        "\n",
        "val_dset = GroceryStoreDataset(\n",
        "    split=\"val\",\n",
        "    transform=tsfms_std,\n",
        ")\n",
        "test_dset = GroceryStoreDataset(\n",
        "    split=\"test\",\n",
        "    transform=tsfms_std,\n",
        ")\n",
        "increased_dataset = torch.utils.data.ConcatDataset([increased_train_dst,train_dset]) #-> augmented data\n",
        "\n",
        "print(f'Train dataset size: {len(train_dset)}')\n",
        "print(f'Increased train dataset size: {len(increased_dataset)}')\n",
        "print(f'Validation dataset size: {len(val_dset)}')\n",
        "print(f'Test dataset size: {len(test_dset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAAHDCAYAAAAKmqQIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1zUlEQVR4nO3de1RVdf7/8RegHFFugQIyIpKal/FSY2pHS0kZ8TKVSX2zrNQxnQospXESV3mrNTjWdzRbXprvNFqNZNk3NbWviZg4Fd4wvngpVjqaNgpO+oOjmMcL+/dHP8/PI6iAwIHzeT7W2mtxPvtz9n6fLfLhxWdffCzLsgQAAAAAXs7X0wUAAAAAQF0g/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYATCDwAAAAAjEH4AAAAAGIHwAwAAAMAIhB8AAAAARiD8ADVszJgxatOmjafLAAA0AIcPH5aPj4+WLVvmaps5c6Z8fHwq9X4fHx/NnDmzRmuKj49XfHx8jW4TqC8IPzCGj49PpZYtW7Z4utRas3//fs2cOVOHDx/2dCkA0ODcf//9atq0qU6fPn3NPqNGjZK/v79OnjxZh5VVnbePB97++VB9jTxdAFBX3nvvPbfX7777rjIzM8u1d+rU6ab281//9V8qKyu7qW3Ulv3792vWrFmKj49ndgoAqmjUqFFau3atVq1apSeffLLc+rNnz2rNmjUaPHiwwsPDq72fl156SVOnTr2ZUm/oeuPBxo0ba3XfdYHxDtdC+IExHn/8cbfX27ZtU2ZmZrn2q509e1ZNmzat9H4aN25crfoAAPXb/fffr6CgIGVkZFQYftasWaPS0lKNGjXqpvbTqFEjNWrkuV/R/P39PbZvoLZx2htwhfj4eHXp0kW5ubnq16+fmjZtqmnTpkn6eVAbNmyYoqOjZbPZ1LZtW73yyiu6dOmS2zauvubn8vncr7/+uv7yl7+obdu2stls6tmzp3bu3HnDmi5cuKBZs2apffv2atKkicLDw3X33XcrMzPTrd+3336rhx56SGFhYWrSpInuvPNOffLJJ671y5Yt08MPPyxJuvfee404zQ8AalJAQIBGjBihrKwsnThxotz6jIwMBQUF6f7779epU6f0+9//Xl27dlVgYKCCg4M1ZMgQ/e///u8N91PRNT9Op1OTJ09WixYtXPv44Ycfyr33+++/17PPPqsOHTooICBA4eHhevjhh91O/7rReFDRNT8nTpzQuHHjFBkZqSZNmqh79+5655133Pow3qEhYOYHuMrJkyc1ZMgQjRw5Uo8//rgiIyMl/fzDNDAwUKmpqQoMDNTmzZs1ffp0ORwOvfbaazfcbkZGhk6fPq3f/e538vHx0dy5czVixAj985//vO5s0cyZM5Wenq6nnnpKvXr1ksPh0K5du7R79279+te/liTt27dPffv21S9+8QtNnTpVzZo104cffqjhw4frv//7v/Xggw+qX79+eu6557RgwQJNmzbNdXrfzZ7mBwAmGTVqlN555x19+OGHSklJcbWfOnVKn332mR599FEFBARo3759Wr16tR5++GHFxcWpqKhIb731lvr376/9+/crOjq6Svt96qmn9Pe//12PPfaY+vTpo82bN2vYsGHl+u3cuVNfffWVRo4cqVatWunw4cNavHix4uPjtX//fjVt2rTK48FPP/2k+Ph4HThwQCkpKYqLi9PKlSs1ZswYFRcX6/nnn3frz3iHes0CDJWcnGxd/V+gf//+liRryZIl5fqfPXu2XNvvfvc7q2nTpta5c+dcbaNHj7ZiY2Ndrw8dOmRJssLDw61Tp0652tesWWNJstauXXvdOrt3724NGzbsun0GDhxode3a1a2OsrIyq0+fPlb79u1dbStXrrQkWZ9//vl1twcAqNjFixetli1bWna73a19yZIlliTrs88+syzLss6dO2ddunTJrc+hQ4csm81mzZ49261NkrV06VJX24wZM9zGp7y8PEuS9eyzz7pt77HHHrMkWTNmzHC1VTRW5eTkWJKsd99919V2vfGgf//+Vv/+/V2v58+fb0my/v73v7vazp8/b9ntdiswMNByOBxun4XxDvUZp70BV7HZbBo7dmy59oCAANfXp0+f1o8//qh77rlHZ8+e1bfffnvD7T7yyCO65ZZbXK/vueceSdI///nP674vNDRU+/bt03fffVfh+lOnTmnz5s36j//4D1ddP/74o06ePKnExER99913+te//nXD+gAAN+bn56eRI0cqJyfH7VSyjIwMRUZGauDAgZJ+Hkt8fX/+NevSpUs6efKkAgMD1aFDB+3evbtK+/z0008lSc8995xb+6RJk8r1vXKsunDhgk6ePKl27dopNDS0yvu9cv9RUVF69NFHXW2NGzfWc889pzNnzig7O9utP+Md6jPCD3CVX/ziFxVe7Llv3z49+OCDCgkJUXBwsFq0aOG6WUJJSckNt9u6dWu315cHhv/zf/7Pdd83e/ZsFRcX67bbblPXrl01ZcoU5efnu9YfOHBAlmXp5ZdfVosWLdyWGTNmSFKF56YDAKrn8g0NMjIyJEk//PCD/vGPf2jkyJHy8/OTJJWVlWnevHlq3769bDabmjdvrhYtWig/P79SY8aVvv/+e/n6+qpt27Zu7R06dCjX96efftL06dMVExPjtt/i4uIq7/fK/bdv394V5i67fBrZ999/79bOeIf6jGt+gKtc+Vezy4qLi9W/f38FBwdr9uzZatu2rZo0aaLdu3frxRdfrNStrS8PiFezLOu67+vXr58OHjyoNWvWaOPGjfrrX/+qefPmacmSJXrqqadc+/7973+vxMTECrfRrl27G9YHAKicHj16qGPHjnr//fc1bdo0vf/++7Isy+0ub3/84x/18ssv67e//a1eeeUVhYWFydfXV5MmTarVxyFMnDhRS5cu1aRJk2S32xUSEiIfHx+NHDmyzh7DwHiH+ozwA1TCli1bdPLkSX388cfq16+fq/3QoUN1sv+wsDCNHTtWY8eO1ZkzZ9SvXz/NnDlTTz31lG699VZJP5+CkJCQcN3tVPaJ4QCA6xs1apRefvll5efnKyMjQ+3bt1fPnj1d6z/66CPde++9evvtt93eV1xcrObNm1dpX7GxsSorK9PBgwfdZnsKCgrK9f3oo480evRo/ed//qer7dy5cyouLnbrV5XxIDY2Vvn5+SorK3Ob/bl8yndsbGylt3UjjHeobZz2BlTC5b9iXflXq/Pnz2vRokW1vu+rnxIeGBiodu3ayel0SpIiIiIUHx+vt956S8ePHy/3/n//+9+ur5s1ayZJ5QZBAEDVXJ7lmT59uvLy8so928fPz6/cTMfKlSurdU3KkCFDJEkLFixwa58/f365vhXt98033yz3WIaqjAdDhw5VYWGhPvjgA1fbxYsX9eabbyowMFD9+/evzMe4IcY71AVmfoBK6NOnj2655RaNHj1azz33nHx8fPTee+/dcAq/JnTu3Fnx8fHq0aOHwsLCtGvXLn300Udut1hduHCh7r77bnXt2lXjx4/XrbfeqqKiIuXk5OiHH35wPVfi9ttvl5+fn/70pz+ppKRENptNAwYMUERERK1/DgDwJnFxcerTp4/WrFkjSeXCz29+8xvNnj1bY8eOVZ8+fbRnzx4tX77cNXtRFbfffrseffRRLVq0SCUlJerTp4+ysrJ04MCBcn1/85vf6L333lNISIg6d+6snJwcbdq0SeHh4eW2WdnxYMKECXrrrbc0ZswY5ebmqk2bNvroo4/05Zdfav78+QoKCqryZ6oI4x3qAuEHqITw8HCtW7dOL7zwgl566SXdcsstevzxxzVw4MBrnndcU5577jl98skn2rhxo5xOp2JjY/Xqq69qypQprj6dO3fWrl27NGvWLC1btkwnT55URESE7rjjDk2fPt3VLyoqSkuWLFF6errGjRunS5cu6fPPP2cwAIBqGDVqlL766iv16tWr3LUm06ZNU2lpqTIyMvTBBx/oV7/6ldavX6+pU6dWa19/+9vf1KJFCy1fvlyrV6/WgAEDtH79esXExLj1e+ONN+Tn56fly5fr3Llz6tu3rzZt2lRurKrKeBAQEKAtW7Zo6tSpeuedd+RwONShQwctXbpUY8aMqdbnqQjjHeqCj1UXf7oGAAAAAA/jmh8AAAAARiD8AAAAADAC4QcAAACAEQg/AAAAAIxA+AEAAABgBMIPAAAAACM0yOf8lJWV6dixYwoKCpKPj4+nywEAY1iWpdOnTys6Olq+vvz97EqMTQDgGVUZmxpk+Dl27Fi5h3oBAOrO0aNH1apVK0+XUa8wNgGAZ1VmbGqQ4ScoKEjSzx8wODjYw9UAgDkcDodiYmJcP4fx/zE2AYBnVGVsapDh5/LpBMHBwQwwAOABDe20rsWLF2vx4sU6fPiwJOmXv/ylpk+friFDhkiSzp07pxdeeEErVqyQ0+lUYmKiFi1apMjIyErvg7EJADyrMmMTJ2wDALxeq1atNGfOHOXm5mrXrl0aMGCAHnjgAe3bt0+SNHnyZK1du1YrV65Udna2jh07phEjRni4agBATfOxLMvydBFV5XA4FBISopKSEv66BgB1yJt+/oaFhem1117TQw89pBYtWigjI0MPPfSQJOnbb79Vp06dlJOTo7vuuqtS2/OmYwMADUlVfv4y8wMAMMqlS5e0YsUKlZaWym63Kzc3VxcuXFBCQoKrT8eOHdW6dWvl5ORccztOp1MOh8NtAQDUb4QfAIAR9uzZo8DAQNlsNj399NNatWqVOnfurMLCQvn7+ys0NNStf2RkpAoLC6+5vfT0dIWEhLgW7vQGAPUf4QcAYIQOHTooLy9P27dv1zPPPKPRo0dr//791d5eWlqaSkpKXMvRo0drsFoAQG1okHd7AwCgqvz9/dWuXTtJUo8ePbRz50698cYbeuSRR3T+/HkVFxe7zf4UFRUpKirqmtuz2Wyy2Wy1XTYAoAYx8wMAMFJZWZmcTqd69Oihxo0bKysry7WuoKBAR44ckd1u92CFAICaxswPAMDrpaWlaciQIWrdurVOnz6tjIwMbdmyRZ999plCQkI0btw4paamKiwsTMHBwZo4caLsdnul7/QGAGgYCD8AAK934sQJPfnkkzp+/LhCQkLUrVs3ffbZZ/r1r38tSZo3b558fX2VlJTk9pBTAIB34Tk/AIBK4+fvtXFsAMAzeM4PAAAAAFyF8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMYOxzftpMXV9h++E5w+q4EgAAgOrjdxqg8pj5AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYATCDwAAAAAjEH4AAAAAGIHwAwAAAMAIhB8AAAAARiD8AAAAADAC4QcAAACAEQg/AAAAAIxA+AEAAABgBMIPAAAAACMQfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBGqFH7S09PVs2dPBQUFKSIiQsOHD1dBQYFbn/j4ePn4+LgtTz/9tFufI0eOaNiwYWratKkiIiI0ZcoUXbx48eY/DQAAAABcQ6OqdM7OzlZycrJ69uypixcvatq0aRo0aJD279+vZs2aufqNHz9es2fPdr1u2rSp6+tLly5p2LBhioqK0ldffaXjx4/rySefVOPGjfXHP/6xBj4SAAAAAJRXpfCzYcMGt9fLli1TRESEcnNz1a9fP1d706ZNFRUVVeE2Nm7cqP3792vTpk2KjIzU7bffrldeeUUvvviiZs6cKX9//2p8DAAAAAC4vpu65qekpESSFBYW5ta+fPlyNW/eXF26dFFaWprOnj3rWpeTk6OuXbsqMjLS1ZaYmCiHw6F9+/bdTDkAAAAAcE1Vmvm5UllZmSZNmqS+ffuqS5curvbHHntMsbGxio6OVn5+vl588UUVFBTo448/liQVFha6BR9JrteFhYUV7svpdMrpdLpeOxyO6pYNAAAAwFDVDj/Jycnau3evvvjiC7f2CRMmuL7u2rWrWrZsqYEDB+rgwYNq27ZttfaVnp6uWbNmVbdUAAAAAKhe+ElJSdG6deu0detWtWrV6rp9e/fuLUk6cOCA2rZtq6ioKO3YscOtT1FRkSRd8zqhtLQ0paamul47HA7FxMRUp3QAAABjtJm6vsL2w3OG1XElQP1QpWt+LMtSSkqKVq1apc2bNysuLu6G78nLy5MktWzZUpJkt9u1Z88enThxwtUnMzNTwcHB6ty5c4XbsNlsCg4OdlsAAAAAoCqqNPOTnJysjIwMrVmzRkFBQa5rdEJCQhQQEKCDBw8qIyNDQ4cOVXh4uPLz8zV58mT169dP3bp1kyQNGjRInTt31hNPPKG5c+eqsLBQL730kpKTk2Wz2Wr+EwI1iL+gAQAANFxVmvlZvHixSkpKFB8fr5YtW7qWDz74QJLk7++vTZs2adCgQerYsaNeeOEFJSUlae3ata5t+Pn5ad26dfLz85Pdbtfjjz+uJ5980u25QAAAAABQ06o082NZ1nXXx8TEKDs7+4bbiY2N1aefflqVXQMAAADATbmp5/wAAAAAQENB+AEAAABgBMIPAAAAACMQfgAAXi89PV09e/ZUUFCQIiIiNHz4cBUUFLj1iY+Pl4+Pj9vy9NNPe6hiAEBtIPwAALxedna2kpOTtW3bNmVmZurChQsaNGiQSktL3fqNHz9ex48fdy1z5871UMUAgNpQpbu9AQDQEG3YsMHt9bJlyxQREaHc3Fz169fP1d60aVNFRUXVdXkAgDrCzA8AwDglJSWSpLCwMLf25cuXq3nz5urSpYvS0tJ09uzZa27D6XTK4XC4LQCA+o2ZHwCAUcrKyjRp0iT17dtXXbp0cbU/9thjio2NVXR0tPLz8/Xiiy+qoKBAH3/8cYXbSU9P16xZs+qqbABADSD8AACMkpycrL179+qLL75wa58wYYLr665du6ply5YaOHCgDh48qLZt25bbTlpamlJTU12vHQ6HYmJiaq9wAMBNI/wAAIyRkpKidevWaevWrWrVqtV1+/bu3VuSdODAgQrDj81mk81mq5U6AQC1g/ADAPB6lmVp4sSJWrVqlbZs2aK4uLgbvicvL0+S1LJly1quDgBQVwg/AACvl5ycrIyMDK1Zs0ZBQUEqLCyUJIWEhCggIEAHDx5URkaGhg4dqvDwcOXn52vy5Mnq16+funXr5uHqAQA1hfADAPB6ixcvlvTzg0yvtHTpUo0ZM0b+/v7atGmT5s+fr9LSUsXExCgpKUkvvfSSB6oFANQWwg8AwOtZlnXd9TExMcrOzq6jagAAnsJzfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYATCDwAAAAAjEH4AAAAAGIHwAwAAAMAIhB8AAAAARiD8AAAAADAC4QcAAACAEQg/AAAAAIxA+AEAAABgBMIPAAAAACMQfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGCERp4uAAAA/KzN1PUVth+eM6yOKwEA78TMDwAAAAAjEH4AAAAAGIHwAwAAAMAIhB8AAAAARiD8AAAAADAC4QcAAACAEQg/AAAAAIxA+AEAAABgBMIPAAAAACNUKfykp6erZ8+eCgoKUkREhIYPH66CggK3PufOnVNycrLCw8MVGBiopKQkFRUVufU5cuSIhg0bpqZNmyoiIkJTpkzRxYsXb/7TAAAAAMA1VCn8ZGdnKzk5Wdu2bVNmZqYuXLigQYMGqbS01NVn8uTJWrt2rVauXKns7GwdO3ZMI0aMcK2/dOmShg0bpvPnz+urr77SO++8o2XLlmn69Ok196kAAAAA4CqNqtJ5w4YNbq+XLVumiIgI5ebmql+/fiopKdHbb7+tjIwMDRgwQJK0dOlSderUSdu2bdNdd92ljRs3av/+/dq0aZMiIyN1++2365VXXtGLL76omTNnyt/fv+Y+HQAAAAD8Pzd1zU9JSYkkKSwsTJKUm5urCxcuKCEhwdWnY8eOat26tXJyciRJOTk56tq1qyIjI119EhMT5XA4tG/fvgr343Q65XA43BYAAAAAqIpqh5+ysjJNmjRJffv2VZcuXSRJhYWF8vf3V2hoqFvfyMhIFRYWuvpcGXwur7+8riLp6ekKCQlxLTExMdUtGwAAAIChqh1+kpOTtXfvXq1YsaIm66lQWlqaSkpKXMvRo0drfZ8AAAAAvEuVrvm5LCUlRevWrdPWrVvVqlUrV3tUVJTOnz+v4uJit9mfoqIiRUVFufrs2LHDbXuX7wZ3uc/VbDabbDZbdUoFAAAAAElVnPmxLEspKSlatWqVNm/erLi4OLf1PXr0UOPGjZWVleVqKygo0JEjR2S32yVJdrtde/bs0YkTJ1x9MjMzFRwcrM6dO9/MZwEAAACAa6rSzE9ycrIyMjK0Zs0aBQUFua7RCQkJUUBAgEJCQjRu3DilpqYqLCxMwcHBmjhxoux2u+666y5J0qBBg9S5c2c98cQTmjt3rgoLC/XSSy8pOTmZ2R0AAAAAtaZK4Wfx4sWSpPj4eLf2pUuXasyYMZKkefPmydfXV0lJSXI6nUpMTNSiRYtcff38/LRu3To988wzstvtatasmUaPHq3Zs2ff3CcBAAAAgOuoUvixLOuGfZo0aaKFCxdq4cKF1+wTGxurTz/9tCq7BgAAAICbclPP+QEAoCFIT09Xz549FRQUpIiICA0fPlwFBQVufc6dO6fk5GSFh4crMDBQSUlJrhvyAAC8A+EHAOD1srOzlZycrG3btikzM1MXLlzQoEGDVFpa6uozefJkrV27VitXrlR2draOHTumESNGeLBqAEBNq9atrgEAaEg2bNjg9nrZsmWKiIhQbm6u+vXrp5KSEr399tvKyMjQgAEDJP18PWunTp20bds21017AAANGzM/AADjlJSUSJLCwsIkSbm5ubpw4YISEhJcfTp27KjWrVsrJyenwm04nU45HA63BQBQvzHzAwAwSllZmSZNmqS+ffuqS5cukqTCwkL5+/u7PaBbkiIjI12Pdbhaenq6Zs2aVdvlNmhtpq6vsP3wnGF1XAm8Cd9XuBnM/AAAjJKcnKy9e/dqxYoVN7WdtLQ0lZSUuJajR4/WUIUAgNrCzA8AwBgpKSlat26dtm7dqlatWrnao6KidP78eRUXF7vN/hQVFSkqKqrCbdlsNh7ODQANDDM/AACvZ1mWUlJStGrVKm3evFlxcXFu63v06KHGjRsrKyvL1VZQUKAjR47IbrfXdbkAgFrCzA8AwOslJycrIyNDa9asUVBQkOs6npCQEAUEBCgkJETjxo1TamqqwsLCFBwcrIkTJ8put3OnNwDwIoQfAIDXW7x4sSQpPj7erX3p0qUaM2aMJGnevHny9fVVUlKSnE6nEhMTtWjRojquFABQmwg/AACvZ1nWDfs0adJECxcu1MKFC+ugIgCAJ3DNDwAAAAAjEH4AAAAAGIHwAwAAAMAIhB8AAAAARiD8AAAAADAC4QcAAACAEbjVNVCD2kxdX2H74TnD6rgSAAAAXI2ZHwAAAABGYOYHwDUxkwUAALwJMz8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYATCDwAAAAAjEH4AAAAAGIHwAwAAAMAIhB8AAAAARiD8AAAAADAC4QcAAACAEQg/AAAAAIxA+AEAAABgBMIPAAAAACMQfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYIRGni4ANaPN1PUVth+eM6yOKwEAAADqpyrP/GzdulX33XefoqOj5ePjo9WrV7utHzNmjHx8fNyWwYMHu/U5deqURo0apeDgYIWGhmrcuHE6c+bMTX0QAAAAALieKoef0tJSde/eXQsXLrxmn8GDB+v48eOu5f3333dbP2rUKO3bt0+ZmZlat26dtm7dqgkTJlS9egAAAACopCqf9jZkyBANGTLkun1sNpuioqIqXPfNN99ow4YN2rlzp+68805J0ptvvqmhQ4fq9ddfV3R0dFVLAgAAAIAbqpUbHmzZskURERHq0KGDnnnmGZ08edK1LicnR6Ghoa7gI0kJCQny9fXV9u3bK9ye0+mUw+FwWwAAAACgKmo8/AwePFjvvvuusrKy9Kc//UnZ2dkaMmSILl26JEkqLCxURESE23saNWqksLAwFRYWVrjN9PR0hYSEuJaYmJiaLhsAAACAl6vxu72NHDnS9XXXrl3VrVs3tW3bVlu2bNHAgQOrtc20tDSlpqa6XjscDgIQAAAAgCqp9ef83HrrrWrevLkOHDggSYqKitKJEyfc+ly8eFGnTp265nVCNptNwcHBbgsAAAAAVEWth58ffvhBJ0+eVMuWLSVJdrtdxcXFys3NdfXZvHmzysrK1Lt379ouBwAAAIChqhx+zpw5o7y8POXl5UmSDh06pLy8PB05ckRnzpzRlClTtG3bNh0+fFhZWVl64IEH1K5dOyUmJkqSOnXqpMGDB2v8+PHasWOHvvzyS6WkpGjkyJHc6Q0AUCtq4hl1AICGr8rhZ9euXbrjjjt0xx13SJJSU1N1xx13aPr06fLz81N+fr7uv/9+3XbbbRo3bpx69Oihf/zjH7LZbK5tLF++XB07dtTAgQM1dOhQ3X333frLX/5Sc58KAIAr1MQz6gAADV+Vb3gQHx8vy7Kuuf6zzz674TbCwsKUkZFR1V0DAFAtN/uMOgCAd6j1a34AAGgIrveMOgCAd6jxW10DANDQDB48WCNGjFBcXJwOHjyoadOmaciQIcrJyZGfn1+F73E6nXI6na7XPIAbAOo/wg8AwHjVeUZdenq6Zs2aVVclAkCNajN1fYXth+cMq+NK6hanvQEAcJWrn1FXkbS0NJWUlLiWo0eP1mGFAIDqYOYHAICrXP2MuorYbDa3O5kCAOo/wg8AwOudOXPGbRbn8jPqwsLCFBYWplmzZikpKUlRUVE6ePCg/vCHP7g9ow4A4B0IPwAAr7dr1y7de++9rtepqamSpNGjR2vx4sXKz8/XO++8o+LiYkVHR2vQoEF65ZVXmNkBAC9D+AEAeL2aeEYdAKDh44YHAAAAAIxA+AEAAABgBMIPAAAAACMQfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEaeboAAED1tZm6vsL2w3OG1XElAADUf8z8AAAAADAC4QcAAACAEQg/AAAAAIxA+AEAAABgBMIPAAAAACMQfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIzTydAEwV5up6ytsPzxnWB1XAgAAABMw8wMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMwN3eAKCWcWdDAADqB2Z+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYATCDwAAAAAjEH4AAAAAGIHwAwAAAMAIVQ4/W7du1X333afo6Gj5+Pho9erVbusty9L06dPVsmVLBQQEKCEhQd99951bn1OnTmnUqFEKDg5WaGioxo0bpzNnztzUBwEAAACA66ly+CktLVX37t21cOHCCtfPnTtXCxYs0JIlS7R9+3Y1a9ZMiYmJOnfunKvPqFGjtG/fPmVmZmrdunXaunWrJkyYUP1PAQAAAAA30KiqbxgyZIiGDBlS4TrLsjR//ny99NJLeuCBByRJ7777riIjI7V69WqNHDlS33zzjTZs2KCdO3fqzjvvlCS9+eabGjp0qF5//XVFR0ffxMcBAAAAgIrV6DU/hw4dUmFhoRISElxtISEh6t27t3JyciRJOTk5Cg0NdQUfSUpISJCvr6+2b99e4XadTqccDofbAgAAAABVUaPhp7CwUJIUGRnp1h4ZGelaV1hYqIiICLf1jRo1UlhYmKvP1dLT0xUSEuJaYmJiarJsAAAAAAZoEHd7S0tLU0lJiWs5evSop0sCADQgNXGzHgBAw1ej4ScqKkqSVFRU5NZeVFTkWhcVFaUTJ064rb948aJOnTrl6nM1m82m4OBgtwUAgMqqiZv1AAAavhoNP3FxcYqKilJWVparzeFwaPv27bLb7ZIku92u4uJi5ebmuvps3rxZZWVl6t27d02WAwCApJ9v1vPqq6/qwQcfLLfu6pv1dOvWTe+++66OHTtWboYIANCwVTn8nDlzRnl5ecrLy5P0800O8vLydOTIEfn4+GjSpEl69dVX9cknn2jPnj168sknFR0dreHDh0uSOnXqpMGDB2v8+PHasWOHvvzyS6WkpGjkyJHc6Q0AUOcqc7MeAIB3qPKtrnft2qV7773X9To1NVWSNHr0aC1btkx/+MMfVFpaqgkTJqi4uFh33323NmzYoCZNmrjes3z5cqWkpGjgwIHy9fVVUlKSFixYUAMfBwCAqqnMzXoq4nQ65XQ6Xa+5EykA1H9VDj/x8fGyLOua6318fDR79mzNnj37mn3CwsKUkZFR1V0DAFBvpKena9asWZ4uA2iQ2kxdX2H74TnD6rgSXIu3/hs1iLu9AQBQWypzs56KcCdSAGh4CD8AAKNV5mY9FeFOpADQ8FT5tDcAABqaM2fO6MCBA67Xl2/WExYWptatW7tu1tO+fXvFxcXp5ZdfdrtZDwDAOxB+AABeryZu1gMAaPgIPwAAr1cTN+sBADR8XPMDAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYATCDwAAAAAjEH4AAAAAGIHwAwAAAMAIhB8AAAAARiD8AAAAADBCI08XAAAAAMB7tJm6vsL2w3OG1XEl5THzAwAAAMAIzPwAgIfV57+QAQDgTZj5AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAre6Bq7CbYcBAAC8EzM/AAAAAIxA+AEAAABgBMIPAAAAACMQfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABihkacLAOBZbaaur7D98JxhdVwJAABA7WLmBwAAAIARCD8AAAAAjMBpbwAAeAFOYQWAGyP8gAETAAAARuC0NwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjFDj4WfmzJny8fFxWzp27Ohaf+7cOSUnJys8PFyBgYFKSkpSUVFRTZcBAAAAAG5qZebnl7/8pY4fP+5avvjiC9e6yZMna+3atVq5cqWys7N17NgxjRgxojbKAAAAAACXWrnVdaNGjRQVFVWuvaSkRG+//bYyMjI0YMAASdLSpUvVqVMnbdu2TXfddVdtlAMAAAAAtRN+vvvuO0VHR6tJkyay2+1KT09X69atlZubqwsXLighIcHVt2PHjmrdurVycnKuGX6cTqecTqfrtcPhqI2yAa/Ec5yAG5s5c6ZmzZrl1tahQwd9++23HqoIAFAbavy0t969e2vZsmXasGGDFi9erEOHDumee+7R6dOnVVhYKH9/f4WGhrq9JzIyUoWFhdfcZnp6ukJCQlxLTExMTZcNADDc9U7ZBgB4hxqf+RkyZIjr627duql3796KjY3Vhx9+qICAgGptMy0tTampqa7XDoeDAAQAqFHXOmUbAOA9av1W16Ghobrtttt04MABRUVF6fz58youLnbrU1RUdN0Bx2azKTg42G0BAKAmXT5l+9Zbb9WoUaN05MiR6/Z3Op1yOBxuCwCgfquVa36udObMGR08eFBPPPGEevToocaNGysrK0tJSUmSpIKCAh05ckR2u722SwEaLK7bAWrX5VO2O3TooOPHj2vWrFm65557tHfvXgUFBVX4nvT09HLXCdWmm/k5cKP3Xm+9p37+1NfPW1t11eZ+G1pNN6O+ft/Ulvr4fVOb760JNR5+fv/73+u+++5TbGysjh07phkzZsjPz0+PPvqoQkJCNG7cOKWmpiosLEzBwcGaOHGi7HY7d3oDAHjM9U7ZHjduXIXv4ZRsAGh4ajz8/PDDD3r00Ud18uRJtWjRQnfffbe2bdumFi1aSJLmzZsnX19fJSUlyel0KjExUYsWLarpMgAAqLYrT9m+FpvNJpvNVodVAQBuVo2HnxUrVlx3fZMmTbRw4UItXLiwpnddb3h6Og8AcHOuPGUbAOA9av2aH29EuAEA73K9U7YBAN6D8AMAMN6NTtkGAHgHwg8AwHg3OmUbAOAdCD8A6h1OLQUAALWB8FPH+KUOAAAA8AzCzzUQUgAAAADv4uvpAgAAAACgLhB+AAAAABiB094AoBI4FRYAgIaP8AMANYBwBAD1X338WX2jmupjzQ0Z4Qe1iv+wAAAAqC+45gcAAACAEZj5MQQzMAAAADAdMz8AAAAAjMDMD4zDLBgAAICZmPkBAAAAYARmfoA6wowTAACAZxF+GhB+efZu/PsCAADULsJPPcMvwAAAAEDt4JofAAAAAEZg5gfwAswYoiJ8XwAA4I7wAwAAqo2QDaAhIfzgpjDowRP4vgMAANXBNT8AAAAAjED4AQAAAGAETntDvXUzpzZxWhQAAACuRvgB4FUIvgAA4Fo47Q0AAACAEQg/AAAAAIzAaW8A8P9wyhwAAN6N8IMGiV9S6z/+jQAAQH3DaW8AAAAAjMDMD26Iv+ADAADAGzDzAwAAAMAIzPwA8AhPzShWtF9mMQEAMAMzPwAAAACMwMwPANRjXHMHAEDNYeYHAAAAgBGY+QFQbcxKAACAhoSZHwAAAABGIPwAAAAAMALhBwAAAIARCD8AAAAAjED4AQAAAGAEwg8AAAAAIxB+AAAAABiB8AMAAADACIQfAAAAAEYg/AAAAAAwAuEHAAAAgBEIPwAAAACMQPgBAAAAYATCDwAAAAAjEH4AAAAAGIHwAwAAAMAIHg0/CxcuVJs2bdSkSRP17t1bO3bs8GQ5AADDMS4BgHfzWPj54IMPlJqaqhkzZmj37t3q3r27EhMTdeLECU+VBAAwGOMSAHg/j4WfP//5zxo/frzGjh2rzp07a8mSJWratKn+9re/eaokAIDBGJcAwPs18sROz58/r9zcXKWlpbnafH19lZCQoJycnHL9nU6nnE6n63VJSYkkyeFwVLuGMufZCtsvb/N66+vje+tjTbyX9zaU99bHmurivdVx+b2WZVV7G/VRVcclqe7Hpvr6fVRb34O1+d7a+rw3U5e3/X5wIw3tON7se6+nvtZcH4/VtVRpbLI84F//+pclyfrqq6/c2qdMmWL16tWrXP8ZM2ZYklhYWFhY6sly9OjRuhoy6kRVxyXLYmxiYWFhqW9LZcYmj8z8VFVaWppSU1Ndr8vKynTq1CmFh4fLx8fnprbtcDgUExOjo0ePKjg4+GZL9Wocq8rjWFUex6py6stxsixLp0+fVnR0tMdqqC8Ym+oHjlXlcJwqj2NVefXlWFVlbPJI+GnevLn8/PxUVFTk1l5UVKSoqKhy/W02m2w2m1tbaGhojdYUHBzMN3glcawqj2NVeRyryqkPxykkJMSj+68NVR2XJMam+oZjVTkcp8rjWFVefThWlR2bPHLDA39/f/Xo0UNZWVmutrKyMmVlZclut3uiJACAwRiXAMAMHjvtLTU1VaNHj9add96pXr16af78+SotLdXYsWM9VRIAwGCMSwDg/TwWfh555BH9+9//1vTp01VYWKjbb79dGzZsUGRkZJ3WYbPZNGPGjHKnLqA8jlXlcawqj2NVORyn2ldfxiWJf++q4FhVDsep8jhWldcQj5WPZXnZ/UoBAAAAoAIee8gpAAAAANQlwg8AAAAAIxB+AAAAABiB8AMAAADACMaHn4ULF6pNmzZq0qSJevfurR07dni6JI/bunWr7rvvPkVHR8vHx0erV692W29ZlqZPn66WLVsqICBACQkJ+u677zxTrAelp6erZ8+eCgoKUkREhIYPH66CggK3PufOnVNycrLCw8MVGBiopKSkcg9RNMHixYvVrVs310PQ7Ha7/ud//se1nuNUsTlz5sjHx0eTJk1ytXGsvB/jUnmMS5XH2FR5jE3V09DHJqPDzwcffKDU1FTNmDFDu3fvVvfu3ZWYmKgTJ054ujSPKi0tVffu3bVw4cIK18+dO1cLFizQkiVLtH37djVr1kyJiYk6d+5cHVfqWdnZ2UpOTta2bduUmZmpCxcuaNCgQSotLXX1mTx5stauXauVK1cqOztbx44d04gRIzxYtWe0atVKc+bMUW5urnbt2qUBAwbogQce0L59+yRxnCqyc+dOvfXWW+rWrZtbO8fKuzEuVYxxqfIYmyqPsanqvGJssgzWq1cvKzk52fX60qVLVnR0tJWenu7BquoXSdaqVatcr8vKyqyoqCjrtddec7UVFxdbNpvNev/99z1QYf1x4sQJS5KVnZ1tWdbPx6Vx48bWypUrXX2++eYbS5KVk5PjqTLrjVtuucX661//ynGqwOnTp6327dtbmZmZVv/+/a3nn3/esiy+p0zAuHRjjEtVw9hUNYxN1+YtY5OxMz/nz59Xbm6uEhISXG2+vr5KSEhQTk6OByur3w4dOqTCwkK34xYSEqLevXsbf9xKSkokSWFhYZKk3NxcXbhwwe1YdezYUa1btzb6WF26dEkrVqxQaWmp7HY7x6kCycnJGjZsmNsxkfie8naMS9XDuHR9jE2Vw9h0Y94yNjXydAGe8uOPP+rSpUvlntwdGRmpb7/91kNV1X+FhYWSVOFxu7zORGVlZZo0aZL69u2rLl26SPr5WPn7+ys0NNStr6nHas+ePbLb7Tp37pwCAwO1atUqde7cWXl5eRynK6xYsUK7d+/Wzp07y63je8q7MS5VD+PStTE23RhjU+V409hkbPgBalJycrL27t2rL774wtOl1FsdOnRQXl6eSkpK9NFHH2n06NHKzs72dFn1ytGjR/X8888rMzNTTZo08XQ5ABo4xqYbY2y6MW8bm4w97a158+by8/MrdyeKoqIiRUVFeaiq+u/yseG4/X8pKSlat26dPv/8c7Vq1crVHhUVpfPnz6u4uNitv6nHyt/fX+3atVOPHj2Unp6u7t2764033uA4XSE3N1cnTpzQr371KzVq1EiNGjVSdna2FixYoEaNGikyMpJj5cUYl6qHcalijE2Vw9h0Y942Nhkbfvz9/dWjRw9lZWW52srKypSVlSW73e7Byuq3uLg4RUVFuR03h8Oh7du3G3fcLMtSSkqKVq1apc2bNysuLs5tfY8ePdS4cWO3Y1VQUKAjR44Yd6wqUlZWJqfTyXG6wsCBA7Vnzx7l5eW5ljvvvFOjRo1yfc2x8l6MS9XDuOSOsenmMDaV53Vjk6fvuOBJK1assGw2m7Vs2TJr//791oQJE6zQ0FCrsLDQ06V51OnTp62vv/7a+vrrry1J1p///Gfr66+/tr7//nvLsixrzpw5VmhoqLVmzRorPz/feuCBB6y4uDjrp59+8nDldeuZZ56xQkJCrC1btljHjx93LWfPnnX1efrpp63WrVtbmzdvtnbt2mXZ7XbLbrd7sGrPmDp1qpWdnW0dOnTIys/Pt6ZOnWr5+PhYGzdutCyL43Q9V95Rx7I4Vt6OcalijEuVx9hUeYxN1deQxyajw49lWdabb75ptW7d2vL397d69eplbdu2zdMledznn39uSSq3jB492rKsn28r+vLLL1uRkZGWzWazBg4caBUUFHi2aA+o6BhJspYuXerq89NPP1nPPvusdcstt1hNmza1HnzwQev48eOeK9pDfvvb31qxsbGWv7+/1aJFC2vgwIGuwcWyOE7Xc/UAw7HyfoxL5TEuVR5jU+UxNlVfQx6bfCzLsupungkAAAAAPMPYa34AAAAAmIXwAwAAAMAIhB8AAAAARiD8AAAAADAC4QcAAACAEQg/AAAAAIxA+AEAAABgBMIPAAAAACMQfgAAAAAYgfADAAAAwAiEHwAAAABGIPwAAAAAMML/BWwdwLZZaO5yAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "###Balancing data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-Showing distribution of test and validation set\n",
        "unique_train_class, counts_train_class = np.unique(train_dset.labels, return_counts=True)\n",
        "unique_val_class, counts_val_class = np.unique(val_dset.labels, return_counts=True)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.bar(unique_train_class, counts_train_class)\n",
        "plt.title('Train set')\n",
        "plt.subplot(1,2,2)\n",
        "plt.bar(unique_val_class, counts_val_class)\n",
        "plt.title('Validation set')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TiNxnjfoil6C"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(\n",
        "    train_dset,\n",
        "    batch_size=cfg_hyp['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "increased_train_dl = DataLoader(\n",
        "    increased_dataset,\n",
        "    batch_size=cfg_hyp['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "balanced_train_dl = DataLoader(\n",
        "    train_dset,\n",
        "    sampler=train_dset.get_sampler(),\n",
        "    batch_size=cfg_hyp['batch_size'],\n",
        ")\n",
        "\n",
        "\n",
        "val_dl = DataLoader(\n",
        "    val_dset,\n",
        "    batch_size=cfg_hyp['batch_size']\n",
        ")\n",
        "test_dl = DataLoader(\n",
        "    test_dset,\n",
        "    batch_size=cfg_hyp['batch_size']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j45zpXZRGNI4"
      },
      "source": [
        "## Utilty function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JVhVloULS51Y"
      },
      "outputs": [],
      "source": [
        "#For saving the result \n",
        "def create_model_directory(model_name, run):\n",
        "    # base_path = f\"/content/drive/MyDrive/model_results_{run}\"\n",
        "    base_path = f\"./model_results_{run}\"\n",
        "    model_path = os.path.join(base_path, model_name)\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "    return model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_8JkwbrjGPOD"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6FSFlsp6ikIY"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, model_name, model_path, stopping_patience = 10, stopping_value = 0.6, scheduler_check=False, WANDB=False):\n",
        "\n",
        "    model.to(device)\n",
        "    best_val_acc = 0.0\n",
        "    if scheduler_check:\n",
        "      scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr = 1e-6)\n",
        "\n",
        "    if device == 'cuda':\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    num_params = count_parameters(model)\n",
        "\n",
        "    run_stats = {\n",
        "        \"model_name\": model_name,\n",
        "        \"num_parameters\": num_params,\n",
        "        \"epochs\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "        if scheduler_check:\n",
        "          scheduler.step(val_loss)\n",
        "          last_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        epoch_stats = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"epoch_time\": epoch_time\n",
        "        }\n",
        "\n",
        "        run_stats[\"epochs\"].append(epoch_stats)\n",
        "\n",
        "        if WANDB:\n",
        "          wandb.log(epoch_stats)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
        "              f\"Time: {epoch_time:.2f}s, \"\n",
        "              f\"Last leraning rate: {last_lr}\")\n",
        "\n",
        "        # Save the best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            early_stopping_counter = 0\n",
        "            torch.save(model.state_dict(), os.path.join(model_path, f\"{model_name}_best.pth\"))\n",
        "            if WANDB:\n",
        "              wandb.save(f\"{model_name}_best.pth\")\n",
        "\n",
        "        else:\n",
        "          early_stopping_counter += 1\n",
        "          print(f\"EarlyStoppingCounter: {early_stopping_counter} out of {stopping_patience}\")\n",
        "\n",
        "        if early_stopping_counter >= stopping_patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        if val_acc > stopping_value:\n",
        "            print(f\"Stopping value reached at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    with open(os.path.join(model_path, f\"{model_name}_run_stats.json\"), \"w\") as f:\n",
        "        json.dump(run_stats, f, indent=2)\n",
        "\n",
        "    return best_val_acc\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_evaluate(model_class, name, train_loader, val_loader, test_loader, num_classes, model_path, num_epochs=50, lr=0.001, wd=1e-5, device='cuda', stopping_patience = 10, stopping_value = 0.6, scheduler_check=False, WANDB=False):\n",
        "\n",
        "    model = model_class(num_classes=num_classes).to(device)\n",
        "    if WANDB:\n",
        "       wandb.init(project=\"grocery-store-classification\", name=name)\n",
        "       wandb.watch(model)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "    best_val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, name, model_path, stopping_patience, stopping_value, scheduler_check, WANDB)\n",
        "\n",
        "    # Load the best model for final evaluation\n",
        "    model.load_state_dict(torch.load(os.path.join(model_path, f\"{name}_best.pth\")))\n",
        "    test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Final results for {name}:\")\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    if WANDB:\n",
        "      wandb.log({\n",
        "          \"best_val_acc\": best_val_acc,\n",
        "          \"test_acc\": test_acc\n",
        "      })\n",
        "\n",
        "    json_path = os.path.join(model_path, f\"{name}_run_stats.json\")\n",
        "    with open(json_path, \"r\") as f:\n",
        "        run_stats = json.load(f)\n",
        "\n",
        "    run_stats[\"best_val_acc\"] = best_val_acc\n",
        "    run_stats[\"test_acc\"] = test_acc\n",
        "\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(run_stats, f, indent=2)\n",
        "\n",
        "    if WANDB:\n",
        "      wandb.finish()\n",
        "\n",
        "\n",
        "    return best_val_acc, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPI3GyHQX0yh"
      },
      "source": [
        "## Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "28YYYZBliHMH"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tc2u857-YoFn"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as Fx\n",
        "\n",
        "##Tutte le reti tranne l'ultima non le ho testate, sono per l ablation study\n",
        "\n",
        "class MoreFullyConnectedNet(nn.Module):   #-> da vedere meglio come farla\n",
        "    def __init__(self, num_classes=43):\n",
        "        super(MoreFullyConnectedNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        #self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(128,256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #out = self.dropout1(out)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #out = self.dropout2(out)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        out = self.fc3(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class NetWithoutBatchNorm(nn.Module):\n",
        "    def __init__(self, num_classes=43):\n",
        "        super(NetWithoutBatchNorm, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        #self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        #out = self.dropout1(out)\n",
        "        x = self.avg_pool(x)\n",
        "        out = x.view(x.size(0), -1)\n",
        "        #out = self.dropout2(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class NetWithoutResidualBlock(nn.Module):\n",
        "    def __init__(self, num_classes=43):\n",
        "        super(NetWithoutResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        #self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        #out = self.dropout1(out)\n",
        "        x = self.avg_pool(x)\n",
        "        out = x.view(x.size(0), -1)\n",
        "        #out = self.dropout2(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class NetWihtoutDropout(nn.Module):\n",
        "    def __init__(self, num_classes=43):\n",
        "        super(NetWihtoutDropout, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = ResidualBlock(64, 64)\n",
        "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
        "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
        "        self.layer4 = ResidualBlock(256, 512, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "#BesttNet -> ResidualBlock + dropout best combination: best performance 0.58 with lr = 1e-3, wd = 1e-5 without scheduler -> da cambiare gli hyp ma ci siamo\n",
        "class GroceryConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=43):\n",
        "        super(GroceryConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = ResidualBlock(64, 64)\n",
        "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
        "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
        "        self.layer4 = ResidualBlock(256, 512, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        #self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        #out = self.dropout1(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.dropout2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "_rVoWDOwjcK5",
        "outputId": "e10d7650-4bab-448c-8c4e-521449331509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Train Loss: 3.4162, Train Acc: 0.1576, Val Loss: 3.1848, Val Acc: 0.2128, Time: 167.57s, Last leraning rate: 0.01\n",
            "Epoch 2/50, Train Loss: 3.0229, Train Acc: 0.2210, Val Loss: 3.0022, Val Acc: 0.2061, Time: 171.06s, Last leraning rate: 0.01\n",
            "EarlyStoppingCounter: 1 out of 10\n",
            "Epoch 3/50, Train Loss: 2.8957, Train Acc: 0.2564, Val Loss: 2.8538, Val Acc: 0.2973, Time: 171.44s, Last leraning rate: 0.01\n",
            "Epoch 4/50, Train Loss: 2.8246, Train Acc: 0.2828, Val Loss: 3.3135, Val Acc: 0.2534, Time: 171.27s, Last leraning rate: 0.01\n",
            "EarlyStoppingCounter: 1 out of 10\n",
            "Epoch 5/50, Train Loss: 2.7482, Train Acc: 0.3023, Val Loss: 2.8638, Val Acc: 0.2939, Time: 171.67s, Last leraning rate: 0.01\n",
            "EarlyStoppingCounter: 2 out of 10\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5d9a5657c0a5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ultimate_cnn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m best_val_acc, test_acc = train_and_evaluate(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-1c01f4cd0b7f>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model_class, name, train_loader, val_loader, test_loader, num_classes, model_path, num_epochs, lr, wd, device, stopping_patience, stopping_value, scheduler_check, WANDB)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWANDB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# Load the best model for final evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-1c01f4cd0b7f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, model_name, model_path, stopping_patience, stopping_value, scheduler_check, WANDB)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtrain_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "####Prova da non guardare\n",
        "model = GroceryConvNet\n",
        "name = 'ultimate_cnn'\n",
        "model_path = create_model_directory(model_name= name, run=1)\n",
        "best_val_acc, test_acc = train_and_evaluate(\n",
        "    model_class = model,\n",
        "    name = name,\n",
        "    train_loader = increased_train_dl,\n",
        "    val_loader = val_dl,\n",
        "    test_loader = test_dl,\n",
        "    num_classes = n_classes,\n",
        "    model_path = model_path,\n",
        "    num_epochs=cfg_hyp['epochs'],\n",
        "    lr=cfg_hyp['lr'],\n",
        "    wd=cfg_hyp['wd'],\n",
        "    device='cuda',\n",
        "    stopping_patience = cfg_hyp['stopping_patience'],\n",
        "    stopping_value = cfg_hyp['stopping_value'],\n",
        "    scheduler_check=True,\n",
        "    WANDB=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "k_WF0Y4kyfMW"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:pw3btykn) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebcd5ae70b6143b5a9d8932901cc4701",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.015 MB uploaded\\r'), FloatProgress(value=0.19695694399482033, max=1."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NetMoreFullyConnected.cnn</strong> at: <a href='https://wandb.ai/rda1027/grocery-store-classification/runs/pw3btykn' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification/runs/pw3btykn</a><br/> View project at: <a href='https://wandb.ai/rda1027/grocery-store-classification' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240902_185705-pw3btykn/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:pw3btykn). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b36038032e6a4619a7896c59bfb9d63c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113741144436062, max=1.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.8 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/media/rda1027/SharedResources/VSC_Documents/VSC_Documents_WSL/1-Year/IPCV/cnn-image-classification/wandb/run-20240902_190519-cgky5x86</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rda1027/grocery-store-classification/runs/cgky5x86' target=\"_blank\">NetMoreFullyConnected.cnn</a></strong> to <a href='https://wandb.ai/rda1027/grocery-store-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rda1027/grocery-store-classification' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rda1027/grocery-store-classification/runs/cgky5x86' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification/runs/cgky5x86</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Train Loss: 3.2879, Train Acc: 0.1646, Val Loss: 3.1167, Val Acc: 0.2027, Time: 57.79s, Last leraning rate: 0.001\n",
            "Epoch 2/50, Train Loss: 2.9973, Train Acc: 0.2191, Val Loss: 2.9649, Val Acc: 0.2230, Time: 58.07s, Last leraning rate: 0.001\n",
            "Epoch 3/50, Train Loss: 2.8550, Train Acc: 0.2462, Val Loss: 2.9155, Val Acc: 0.2162, Time: 58.12s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 1 out of 10\n",
            "Epoch 4/50, Train Loss: 2.7575, Train Acc: 0.2670, Val Loss: 2.9833, Val Acc: 0.2027, Time: 57.72s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 2 out of 10\n",
            "Epoch 5/50, Train Loss: 2.6979, Train Acc: 0.2890, Val Loss: 2.8699, Val Acc: 0.2365, Time: 57.43s, Last leraning rate: 0.001\n",
            "Epoch 6/50, Train Loss: 2.5834, Train Acc: 0.3218, Val Loss: 2.8119, Val Acc: 0.2568, Time: 60.44s, Last leraning rate: 0.001\n",
            "Epoch 7/50, Train Loss: 2.4959, Train Acc: 0.3430, Val Loss: 2.7630, Val Acc: 0.2770, Time: 64.05s, Last leraning rate: 0.001\n",
            "Epoch 8/50, Train Loss: 2.4195, Train Acc: 0.3748, Val Loss: 2.5651, Val Acc: 0.3243, Time: 61.38s, Last leraning rate: 0.001\n",
            "Epoch 9/50, Train Loss: 2.3266, Train Acc: 0.4000, Val Loss: 2.6730, Val Acc: 0.3074, Time: 57.19s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 1 out of 10\n",
            "Epoch 10/50, Train Loss: 2.2768, Train Acc: 0.4176, Val Loss: 2.6323, Val Acc: 0.2905, Time: 57.31s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 2 out of 10\n",
            "Epoch 11/50, Train Loss: 2.2047, Train Acc: 0.4424, Val Loss: 2.5738, Val Acc: 0.3041, Time: 57.30s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 3 out of 10\n",
            "Epoch 12/50, Train Loss: 2.1653, Train Acc: 0.4551, Val Loss: 2.6464, Val Acc: 0.2770, Time: 57.50s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 4 out of 10\n",
            "Epoch 13/50, Train Loss: 2.1025, Train Acc: 0.4828, Val Loss: 2.6350, Val Acc: 0.2905, Time: 56.96s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 5 out of 10\n",
            "Epoch 14/50, Train Loss: 2.0701, Train Acc: 0.4941, Val Loss: 2.4187, Val Acc: 0.3142, Time: 56.98s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 6 out of 10\n",
            "Epoch 15/50, Train Loss: 2.0222, Train Acc: 0.5087, Val Loss: 2.5784, Val Acc: 0.3209, Time: 57.13s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 7 out of 10\n",
            "Epoch 16/50, Train Loss: 1.9796, Train Acc: 0.5269, Val Loss: 2.4712, Val Acc: 0.3750, Time: 57.17s, Last leraning rate: 0.001\n",
            "Epoch 17/50, Train Loss: 1.9583, Train Acc: 0.5398, Val Loss: 2.5063, Val Acc: 0.3581, Time: 57.72s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 1 out of 10\n",
            "Epoch 18/50, Train Loss: 1.9192, Train Acc: 0.5428, Val Loss: 2.5661, Val Acc: 0.3716, Time: 58.31s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 2 out of 10\n",
            "Epoch 19/50, Train Loss: 1.8927, Train Acc: 0.5652, Val Loss: 2.6854, Val Acc: 0.3176, Time: 58.84s, Last leraning rate: 0.001\n",
            "EarlyStoppingCounter: 3 out of 10\n",
            "Epoch 20/50, Train Loss: 1.8597, Train Acc: 0.5778, Val Loss: 2.4630, Val Acc: 0.3784, Time: 58.15s, Last leraning rate: 0.0005\n",
            "Epoch 21/50, Train Loss: 1.7761, Train Acc: 0.6083, Val Loss: 2.5053, Val Acc: 0.3649, Time: 58.18s, Last leraning rate: 0.0005\n",
            "EarlyStoppingCounter: 1 out of 10\n",
            "Epoch 22/50, Train Loss: 1.7401, Train Acc: 0.6239, Val Loss: 2.6129, Val Acc: 0.3581, Time: 57.92s, Last leraning rate: 0.0005\n",
            "EarlyStoppingCounter: 2 out of 10\n",
            "Epoch 23/50, Train Loss: 1.7251, Train Acc: 0.6314, Val Loss: 2.5552, Val Acc: 0.3581, Time: 58.14s, Last leraning rate: 0.0005\n",
            "EarlyStoppingCounter: 3 out of 10\n",
            "Epoch 24/50, Train Loss: 1.7176, Train Acc: 0.6280, Val Loss: 2.5894, Val Acc: 0.3446, Time: 57.53s, Last leraning rate: 0.0005\n",
            "EarlyStoppingCounter: 4 out of 10\n",
            "Epoch 25/50, Train Loss: 1.6947, Train Acc: 0.6483, Val Loss: 2.5684, Val Acc: 0.3649, Time: 57.34s, Last leraning rate: 0.0005\n",
            "EarlyStoppingCounter: 5 out of 10\n",
            "Epoch 26/50, Train Loss: 1.6932, Train Acc: 0.6432, Val Loss: 2.5454, Val Acc: 0.3716, Time: 57.59s, Last leraning rate: 0.00025\n",
            "EarlyStoppingCounter: 6 out of 10\n",
            "Epoch 27/50, Train Loss: 1.6273, Train Acc: 0.6674, Val Loss: 2.5074, Val Acc: 0.3716, Time: 57.57s, Last leraning rate: 0.00025\n",
            "EarlyStoppingCounter: 7 out of 10\n",
            "Epoch 28/50, Train Loss: 1.6305, Train Acc: 0.6759, Val Loss: 2.5558, Val Acc: 0.3682, Time: 57.27s, Last leraning rate: 0.00025\n",
            "EarlyStoppingCounter: 8 out of 10\n",
            "Epoch 29/50, Train Loss: 1.6178, Train Acc: 0.6750, Val Loss: 2.5918, Val Acc: 0.3716, Time: 57.32s, Last leraning rate: 0.00025\n",
            "EarlyStoppingCounter: 9 out of 10\n",
            "Epoch 30/50, Train Loss: 1.6057, Train Acc: 0.6822, Val Loss: 2.5835, Val Acc: 0.3514, Time: 57.42s, Last leraning rate: 0.00025\n",
            "EarlyStoppingCounter: 10 out of 10\n",
            "Early stopping triggered at epoch 30\n",
            "Final results for NetMoreFullyConnected.cnn:\n",
            "Best Validation Accuracy: 0.3784\n",
            "Test Accuracy: 0.4805\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "294efad5cccd4295a01b6ab691461c27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.25475890985324945, max=1."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>epoch_time</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.37838</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>epoch_time</td><td>57.42233</td></tr><tr><td>test_acc</td><td>0.48048</td></tr><tr><td>train_acc</td><td>0.6822</td></tr><tr><td>train_loss</td><td>1.60572</td></tr><tr><td>val_acc</td><td>0.35135</td></tr><tr><td>val_loss</td><td>2.58349</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NetMoreFullyConnected.cnn</strong> at: <a href='https://wandb.ai/rda1027/grocery-store-classification/runs/cgky5x86' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification/runs/cgky5x86</a><br/> View project at: <a href='https://wandb.ai/rda1027/grocery-store-classification' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240902_190519-cgky5x86/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb2b7bae8d4a408db8be82b161885ce1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112627044430055, max=1.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.8 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/media/rda1027/SharedResources/VSC_Documents/VSC_Documents_WSL/1-Year/IPCV/cnn-image-classification/wandb/run-20240902_193447-hrbryy4k</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rda1027/grocery-store-classification/runs/hrbryy4k' target=\"_blank\">NetWithoutBatchNorm.cnn</a></strong> to <a href='https://wandb.ai/rda1027/grocery-store-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rda1027/grocery-store-classification' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rda1027/grocery-store-classification/runs/hrbryy4k' target=\"_blank\">https://wandb.ai/rda1027/grocery-store-classification/runs/hrbryy4k</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.06 GiB. GPU ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     model, model_name \u001b[38;5;241m=\u001b[39m exp\n\u001b[1;32m      9\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m create_model_directory(model_name\u001b[38;5;241m=\u001b[39m model_name, run\u001b[38;5;241m=\u001b[39mrun)\n\u001b[0;32m---> 10\u001b[0m     best_val_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# name = name,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mincreased_train_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_patience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstopping_patience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstopping_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscheduler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mWANDB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[23], line 131\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model_class, name, train_loader, val_loader, test_loader, num_classes, model_path, num_epochs, lr, wd, device, stopping_patience, stopping_value, scheduler_check, WANDB)\u001b[0m\n\u001b[1;32m    128\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    129\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mwd)\n\u001b[0;32m--> 131\u001b[0m best_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopping_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopping_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWANDB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Load the best model for final evaluation\u001b[39;00m\n\u001b[1;32m    134\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_best.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
            "Cell \u001b[0;32mIn[23], line 34\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, model_name, model_path, stopping_patience, stopping_value, scheduler_check, WANDB)\u001b[0m\n\u001b[1;32m     31\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[27], line 44\u001b[0m, in \u001b[0;36mNetWithoutBatchNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))\n\u001b[0;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#out = self.dropout1(out)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_pool(x)\n",
            "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.06 GiB. GPU "
          ]
        }
      ],
      "source": [
        "##Ciclo sui modelli da testare su una cpu capace -> uso data augmentation, learning scheduler e batch_size = 32\n",
        "model = [MoreFullyConnectedNet, NetWithoutBatchNorm, NetWithoutResidualBlock, NetWihtoutDropout, GroceryConvNet]\n",
        "model_name = ['NetMoreFullyConnected.cnn', 'NetWithoutBatchNorm.cnn', 'NetWithoutResidualBlock.cnn', 'NetWihtoutDropout.cnn', 'GroceryConvNet.cnn']\n",
        "experiments = zip(model, model_name)\n",
        "\n",
        "for run in range(1,4): #-> se volessi fare pi run ma per questioni tempo-gpu la escluderei\n",
        "  for exp in experiments:\n",
        "    model, model_name = exp\n",
        "    model_path = create_model_directory(model_name= model_name, run=run)\n",
        "    best_val_acc, test_acc = train_and_evaluate(\n",
        "    model_class = model,\n",
        "    # name = name,\n",
        "    name = model_name,\n",
        "    train_loader = increased_train_dl,\n",
        "    val_loader = val_dl,\n",
        "    test_loader = test_dl,\n",
        "    num_classes = n_classes,\n",
        "    model_path = model_path,\n",
        "    num_epochs=cfg_hyp['epochs'],\n",
        "    lr=cfg_hyp['lr'],\n",
        "    wd=cfg_hyp['wd'],\n",
        "    device=cfg_hyp['device'],\n",
        "    stopping_patience = cfg_hyp['stopping_patience'],\n",
        "    stopping_value = cfg_hyp['stopping_value'],\n",
        "    scheduler_check=cfg_hyp['scheduler'],\n",
        "    WANDB=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD0p2LTNz24o"
      },
      "outputs": [],
      "source": [
        "##Iperparametri mi sa che ha senso poi farlo manualmente\n",
        "# - Impostando scheduler come False (partendo lr di 1e-3)\n",
        "# - Passando train_dl\n",
        "# - Cambiando il batch size (16, 64) ???\n",
        "# - Passando il dataset bilanciato\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A7dzY-Bmy9p"
      },
      "source": [
        "COSA RESTA DA FARE:\n",
        "- Testare sulle varie reti plottando i vari grafici (farlo in locale sarebbe fighissimo, capiamo)\n",
        "- Sulla rete migliore variare gli iperparametri (come no o si scheduler o per leraning rate o comunque qualcosa legato al learning rate, batch_size, si e no data augmentation)\n",
        "\n",
        "-> cos in totale avrei 5 grafici per le reti e 4 per gli iperparametri\n",
        "\n",
        "- Migliorare questione scheduler perch effettivamente anche con true non so se sta funzionando\n",
        "\n",
        "- Usare nn.Sequential (?) cos necessario (?)\n",
        "\n",
        "Alla fine meglio fare ablation study per capire sia riguardo gli iperparamentri che la rete quale  il milgioramento pi efficace"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
