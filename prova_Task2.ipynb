{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA is available? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'PyTorch CUDA is available? {torch.cuda.is_available()}')\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_random(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devices available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroceryStoreDataset(Dataset):\n",
    "\n",
    "    def __init__(self, split: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = Path(\"GroceryStoreDataset/dataset\")\n",
    "        self.split = split\n",
    "        self.paths, self.labels = self.read_file()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "        img = Image.open(self.root / self.paths[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def read_file(self) -> Tuple[List[str], List[int]]:\n",
    "        paths = []\n",
    "        labels = []\n",
    "\n",
    "        with open(self.root / f\"{self.split}.txt\") as f:\n",
    "            for line in f:\n",
    "                # path, fine-grained class, coarse-grained class\n",
    "                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n",
    "                paths.append(path), labels.append(int(label))\n",
    "\n",
    "        return paths, labels\n",
    "\n",
    "    def get_num_classes(self) -> int:\n",
    "        return max(self.labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5280\n"
     ]
    }
   ],
   "source": [
    "## Rimettere a 260x260\n",
    "\n",
    "tsfms_std = T.Compose([\n",
    "    T.Resize(size=(224, 224)),\n",
    "    T.ToTensor(),\n",
    "    # T.Lambda(lambda x: x.flatten()),\n",
    "])\n",
    "\n",
    "tsfms_increasing = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomResizedCrop(size=(150, 150), scale=(0.7, 0.9)),\n",
    "    T.ToTensor(),\n",
    "    T.Resize(size=(224, 224)),\n",
    "    # T.Lambda(lambda x: x.flatten()),\n",
    "])\n",
    "\n",
    "train_dset = GroceryStoreDataset(\n",
    "    split=\"train\",\n",
    "    transform=tsfms_std,\n",
    ")\n",
    "increased_train_dst = GroceryStoreDataset(\n",
    "    split=\"train\",\n",
    "    transform=tsfms_increasing,\n",
    ")\n",
    "val_dset = GroceryStoreDataset(\n",
    "    split=\"val\",\n",
    "    transform=tsfms_std,\n",
    ")\n",
    "test_dset = GroceryStoreDataset(\n",
    "    split=\"test\",\n",
    "    transform=tsfms_std,\n",
    ")\n",
    "n_classes = 43\n",
    "input_dim = len(train_dset[0][0])\n",
    "\n",
    "increased_dataset = torch.utils.data.ConcatDataset([increased_train_dst,train_dset])\n",
    "print(len(increased_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640\n",
      "296\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dset))\n",
    "print(len(val_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    test_dset,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18(torch.nn.Module):\n",
    "    def __init__(self, n_classes, weights):\n",
    "        super().__init__()\n",
    "        self.base_model = resnet18(weights=weights)\n",
    "        self.base_model.fc = torch.nn.Linear(self.base_model.fc.in_features, n_classes)\n",
    "    \n",
    "    def set_requires_grad(self, layer, train):\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = train\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Resnet18(\n",
    "    n_classes=n_classes,\n",
    "    weights=ResNet18_Weights.IMAGENET1K_V1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pushed_net = resnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Freeze base model layer (not fc)\n",
    "for layer in [pushed_net.base_model.conv1, pushed_net.base_model.bn1, pushed_net.base_model.layer1, pushed_net.base_model.layer2, pushed_net.base_model.layer3, pushed_net.base_model.layer4]:\n",
    "    pushed_net.set_requires_grad(layer, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-3\n",
    "optimizer = AdamW(pushed_net.parameters(), lr=initial_lr, weight_decay=1e-4)\n",
    "num_epochs = 30\n",
    "num_steps = num_epochs * len(train_dl)\n",
    "lr_scheduler = OneCycleLR(optimizer, initial_lr, total_steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncorrect(scores, y):\n",
    "    y_hat = torch.argmax(scores, -1)\n",
    "    return (y_hat == y).sum()\n",
    "\n",
    "def accuracy(scores, y):\n",
    "    correct = ncorrect(scores, y)\n",
    "    return correct.true_divide(y.shape[0])\n",
    "\n",
    "def train_loop(model, train_dl, epochs, opt, scheduler, val_dl=None, verbose=False):\n",
    "    best_val_acc = 0\n",
    "    best_params = []\n",
    "    best_epoch = -1\n",
    "\n",
    "    for e in tqdm(range(epochs)):\n",
    "    # for e in range(epochs):\n",
    "        model.train()\n",
    "        # Train\n",
    "        train_loss = 0\n",
    "        train_samples = 0\n",
    "        train_acc = 0\n",
    "        # running_loss = 0\n",
    "        # correct = 0\n",
    "        # total = 0\n",
    "        for train_data in train_dl:\n",
    "            imgs = train_data[0].to(device)\n",
    "            labels = train_data[1].to(device)\n",
    "\n",
    "            opt.zero_grad()  # clear\n",
    "\n",
    "            scores = model(imgs)\n",
    "            loss = F.cross_entropy(scores, labels)\n",
    "\n",
    "            loss.backward()  # fill\n",
    "            opt.step()       # Weight Optimizer step\n",
    "            scheduler.step() # Learning Rate Scheduler step\n",
    "\n",
    "\n",
    "            # running_loss += loss.item()\n",
    "            # _, predicted = torch.max(scores.data, 1)\n",
    "            # total += labels.size(0)\n",
    "            # correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_loss += loss.item() * imgs.shape[0]\n",
    "            train_samples += imgs.shape[0]\n",
    "            train_acc += ncorrect(scores, labels).item()\n",
    "\n",
    "            \n",
    "        # train_loss = running_loss / len(train_dl)\n",
    "        # train_acc = 100 * correct / total\n",
    "        train_acc /= train_samples\n",
    "        train_loss /= train_samples\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_samples = 0\n",
    "            val_acc = 0\n",
    "            # correct = 0\n",
    "            # total = 0\n",
    "            if val_dl is not None:\n",
    "                for val_data in val_dl:\n",
    "                    imgs = val_data[0].to(device)\n",
    "                    labels = val_data[1].to(device)\n",
    "                    val_scores = model(imgs)\n",
    "                    val_loss += F.cross_entropy(val_scores, labels).item() * imgs.shape[0]\n",
    "\n",
    "                    val_samples += imgs.shape[0]\n",
    "                    val_acc += ncorrect(val_scores, labels).item()\n",
    "\n",
    "                    # val_scores = model(imgs)\n",
    "                    # _, predicted = torch.max(val_scores.data, 1)\n",
    "                    # total += labels.size(0)\n",
    "                    # correct += (predicted == labels).sum().item()\n",
    "\n",
    "                val_acc /= val_samples\n",
    "                val_loss /= val_samples\n",
    "                # val_acc = 100 * correct / total\n",
    "\n",
    "            if val_dl is None or val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc if val_dl is not None else 0\n",
    "                best_params = model.state_dict()\n",
    "                torch.save(best_params, \"best_model2.pth\")\n",
    "                best_epoch = e\n",
    "\n",
    "        # if verbose and e % 5 == 0:\n",
    "        if verbose:\n",
    "            print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if val_dl is None else f\" - valid loss {val_loss:.3f} - valid acc {val_acc:.3f}\"))\n",
    "            # print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if val_dl is None else f\" - valid loss - valid acc {val_acc:.3f}\"))\n",
    "\n",
    "    if verbose and val_dl is not None:\n",
    "        print(f\"Best epoch {best_epoch}, best acc {best_val_acc}\")\n",
    "\n",
    "    return best_val_acc, best_params, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dde37bf9be4f809dfcb8ed099ecb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 3.995 - train acc 0.013 - valid loss 3.847 - valid acc 0.034\n",
      "Epoch 1: train loss 3.645 - train acc 0.034 - valid loss 3.529 - valid acc 0.047\n",
      "Epoch 2: train loss 3.286 - train acc 0.075 - valid loss 3.296 - valid acc 0.078\n",
      "Epoch 3: train loss 2.949 - train acc 0.197 - valid loss 2.976 - valid acc 0.196\n",
      "Epoch 4: train loss 2.546 - train acc 0.356 - valid loss 2.636 - valid acc 0.314\n",
      "Epoch 5: train loss 2.120 - train acc 0.495 - valid loss 2.304 - valid acc 0.405\n",
      "Epoch 6: train loss 1.714 - train acc 0.627 - valid loss 2.036 - valid acc 0.476\n",
      "Epoch 7: train loss 1.389 - train acc 0.718 - valid loss 1.803 - valid acc 0.500\n",
      "Epoch 8: train loss 1.151 - train acc 0.776 - valid loss 1.609 - valid acc 0.588\n",
      "Epoch 9: train loss 0.961 - train acc 0.840 - valid loss 1.496 - valid acc 0.608\n",
      "Epoch 10: train loss 0.820 - train acc 0.875 - valid loss 1.382 - valid acc 0.618\n",
      "Epoch 11: train loss 0.715 - train acc 0.902 - valid loss 1.331 - valid acc 0.652\n",
      "Epoch 12: train loss 0.640 - train acc 0.908 - valid loss 1.282 - valid acc 0.679\n",
      "Epoch 13: train loss 0.568 - train acc 0.927 - valid loss 1.217 - valid acc 0.652\n",
      "Epoch 14: train loss 0.521 - train acc 0.938 - valid loss 1.183 - valid acc 0.669\n",
      "Epoch 15: train loss 0.478 - train acc 0.940 - valid loss 1.161 - valid acc 0.679\n",
      "Epoch 16: train loss 0.439 - train acc 0.947 - valid loss 1.137 - valid acc 0.699\n",
      "Epoch 17: train loss 0.414 - train acc 0.952 - valid loss 1.117 - valid acc 0.696\n",
      "Epoch 18: train loss 0.389 - train acc 0.949 - valid loss 1.109 - valid acc 0.686\n",
      "Epoch 19: train loss 0.382 - train acc 0.958 - valid loss 1.085 - valid acc 0.693\n",
      "Epoch 20: train loss 0.361 - train acc 0.960 - valid loss 1.085 - valid acc 0.686\n",
      "Epoch 21: train loss 0.346 - train acc 0.967 - valid loss 1.071 - valid acc 0.703\n",
      "Epoch 22: train loss 0.337 - train acc 0.966 - valid loss 1.065 - valid acc 0.689\n",
      "Epoch 23: train loss 0.325 - train acc 0.964 - valid loss 1.060 - valid acc 0.693\n",
      "Epoch 24: train loss 0.328 - train acc 0.966 - valid loss 1.066 - valid acc 0.689\n",
      "Epoch 25: train loss 0.317 - train acc 0.970 - valid loss 1.066 - valid acc 0.696\n",
      "Epoch 26: train loss 0.311 - train acc 0.970 - valid loss 1.045 - valid acc 0.703\n",
      "Epoch 27: train loss 0.311 - train acc 0.971 - valid loss 1.063 - valid acc 0.699\n",
      "Epoch 28: train loss 0.312 - train acc 0.973 - valid loss 1.051 - valid acc 0.703\n",
      "Epoch 29: train loss 0.310 - train acc 0.970 - valid loss 1.046 - valid acc 0.709\n",
      "Best epoch 29, best acc 0.7094594594594594\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, best_params, best_epoch = train_loop(\n",
    "    pushed_net,\n",
    "    train_dl,\n",
    "    num_epochs,\n",
    "    optimizer,\n",
    "    lr_scheduler,\n",
    "    val_dl,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
